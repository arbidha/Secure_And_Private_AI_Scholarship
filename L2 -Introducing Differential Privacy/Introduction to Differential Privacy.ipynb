{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson : Differential privacy \n",
    "\n",
    "Differential privacy is ensuring that our neural networks are learning from sensitive data,that they're only learning what they're supposed to learn from the data without accidentally learning what they're not supposed to learn from the data.\n",
    "\n",
    "Differential privacy is actually quite a new field.It recently started with statistical database queries around 2003 and even more recently,has been applied to contexts such as Machine Learning.**The general goal of differential privacy is to ensure that different kinds of statistical analysis don't compromise privacy.** \n",
    "\n",
    "\n",
    "Statistical analysis, means in the most general term of,\n",
    "we have some training data or database or just a dataset about individuals and we want to make sure that our statistical analysis of that dataset does not compromise the privacy of any particular individual contained within that dataset.\n",
    "\n",
    "In order to be able to accomplish this goal,we first need to propose a robust definition of privacy. \n",
    "\n",
    "**Privacy** is preserved if, after the analysis,the analyzer doesn't know anything about the people in the dataset.They remain $\"unobserved\"$.\n",
    "\n",
    "But if you think about this definition of privacy in the context of your home and why you have blinds in the front door,and all these things, it's to ensure that information about you doesn't leak at all. However, in the context of statistics,this is really insufficient and really in all cases of Machine Learning because we're trying to learn something about a dataset without learning specific things about individuals which might be sensitive or might harm them in some way.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Canonical Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1,  ..., 0, 1, 0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "num_entries = 5000\n",
    "\n",
    "db = torch.rand(num_entries) > 0.5\n",
    "\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
