{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Project: Varying Amounts of Noise**\n",
    "In this project,**augment the randomized response query from the previous project to allow for varying amounts of randomness to be added**. Specifically, I want you to bias the coin flip to be higher or lower and then run the same experiment.\n",
    "\n",
    "Note - this one is a bit tricker than you might expect. \n",
    "* Add a new parameter to the query function. It will now accept the database and some noise paramter which is a percentage. \n",
    "* Properly rebalance the result of the query given this adjustable parameter.\n",
    "* You need to both adjust the likelihood of the first coin flip AND the de-skewing at the end (where we create the \"augmented_result\" variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database\n",
    "\n",
    "import torch\n",
    "\n",
    "num_entries = 5000\n",
    "\n",
    "db = torch.rand(num_entries) > 0.5\n",
    "\n",
    "db\n",
    "\n",
    "# Create a function - To Remove Index\n",
    "def get_parallel_db(db, remove_index):\n",
    "    return torch.cat((db[0:remove_index],db[remove_index+1:]))\n",
    "\n",
    "# Create Function 2 to iterate through db and create parallel db\n",
    "\n",
    "def get_parallel_dbs(db):\n",
    "    parallel_dbs = list()\n",
    "    for i in range(len(db)):\n",
    "        pdb = get_parallel_db(db,i)\n",
    "        parallel_dbs.append(pdb)\n",
    "    return parallel_dbs\n",
    "\n",
    "# Function 3 to \n",
    "def create_db_and_parallels(num_entries):\n",
    "    db = torch.rand(num_entries) > 0.5\n",
    "    pdbs = get_parallel_dbs(db)\n",
    "    \n",
    "    return db, pdbs\n",
    "\n",
    "#function sensitivity\n",
    "def sensitivity(query, n_entries = 1000):\n",
    "    #Initialize a database of correct size and all parallel database\n",
    "    db , pdbs = create_db_and_parallels(n_entries)\n",
    "    full_db_result = query(db)\n",
    "    #Run the Query over all the databases\n",
    "    max_distance = 0 \n",
    "    for pdb in pdbs:\n",
    "        pdb_result = query(pdb)\n",
    "        # comapre paralled db and full db\n",
    "        db_distance = torch.abs(pdb_result - full_db_result)\n",
    "        if(db_distance > max_distance):\n",
    "            max_distance = db_distance\n",
    "    #Return the sensitivity\n",
    "    return max_distance\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4988)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_result = torch.mean(db.float())\n",
    "true_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1,  ..., 1, 0, 1], dtype=torch.uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# orginal local data or actual value from people\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db, pdbs = create_db_and_parallels(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pack all in the query\n",
    "def query(db):\n",
    "    true_result = torch.mean(db.float())\n",
    "    first_coin_flip = (torch.rand(len(db)) > 0.5).float()\n",
    "    second_coin_flip = (torch.rand(len(db)) > 0.5).float()\n",
    "    augmented_db = (db.float() * first_coin_flip) + (1 - first_coin_flip) * second_coin_flip\n",
    "    db_result = torch.mean(augmented_db.float()) * 2 - 0.5 \n",
    "    \n",
    "    return db_result, true_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project add varying amount of noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pack all in the query\n",
    "def query(db, noise):\n",
    "    true_result = torch.mean(db.float())\n",
    "    # noise \n",
    "    #noise = 0.2\n",
    "    first_coin_flip = (torch.rand(len(db)) > noise).float()\n",
    "    second_coin_flip = (torch.rand(len(db)) > 0.5).float()\n",
    "    \n",
    "    augmented_db = (db.float() * first_coin_flip) + (1 - first_coin_flip) * second_coin_flip\n",
    "    \n",
    "    sk_result =  augmented_db.float().mean() \n",
    "    private_results = ((sk_result / noise) - 0.5) * noise / (1 - noise)\n",
    "    \n",
    "    return sk_result, private_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with noise:tensor(0.7000)\n",
      "withot noise:tensor(0.5000)\n"
     ]
    }
   ],
   "source": [
    "db, pdbs = create_db_and_parallels(10)\n",
    "private_results , true_results = query(db)\n",
    "print(\"with noise:\" + str(private_results))\n",
    "print(\"withot noise:\" + str(true_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_results = ((sk_result / noise) - 0.5) * noise / (1 - noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6250)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "private_results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with noise:tensor(0.3000)\n",
      "withot noise:tensor(0.2500)\n"
     ]
    }
   ],
   "source": [
    "db, pdbs = create_db_and_parallels(10)\n",
    "private_results , true_results = query(db,noise=0.2)\n",
    "print(\"with noise:\" + str(private_results))\n",
    "print(\"withot noise:\" + str(true_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with noise:tensor(0.5600)\n",
      "withot noise:tensor(0.5667)\n"
     ]
    }
   ],
   "source": [
    "db, pdbs = create_db_and_parallels(100)\n",
    "private_results , true_results = query(db,noise=0.1)\n",
    "print(\"with noise:\" + str(private_results))\n",
    "print(\"withot noise:\" + str(true_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with noise:tensor(0.5700)\n",
      "withot noise:tensor(0.5875)\n"
     ]
    }
   ],
   "source": [
    "db, pdbs = create_db_and_parallels(100)\n",
    "private_results , true_results = query(db,noise=0.2)\n",
    "print(\"with noise:\" + str(private_results))\n",
    "print(\"withot noise:\" + str(true_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with noise:tensor(0.5000)\n",
      "withot noise:tensor(0.5000)\n"
     ]
    }
   ],
   "source": [
    "db, pdbs = create_db_and_parallels(100)\n",
    "private_results , true_results = query(db,noise=0.3)\n",
    "print(\"with noise:\" + str(private_results))\n",
    "print(\"withot noise:\" + str(true_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with noise:tensor(0.5300)\n",
      "withot noise:tensor(0.5500)\n"
     ]
    }
   ],
   "source": [
    "db, pdbs = create_db_and_parallels(100)\n",
    "private_results , true_results = query(db,noise=0.4)\n",
    "print(\"with noise:\" + str(private_results))\n",
    "print(\"withot noise:\" + str(true_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with noise:tensor(0.5900)\n",
      "withot noise:tensor(0.6800)\n"
     ]
    }
   ],
   "source": [
    "db, pdbs = create_db_and_parallels(100)\n",
    "private_results , true_results = query(db,noise=0.5)\n",
    "print(\"with noise:\" + str(private_results))\n",
    "print(\"withot noise:\" + str(true_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of the dataset allows you to add more noise or more privacy protection to individual who are insiode the dataset.\n",
    "The more private data you have access to , the easire it is to protect the privacy of the people who are involved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with noise:tensor(0.5170)\n",
      "withot noise:tensor(0.5340)\n"
     ]
    }
   ],
   "source": [
    "db, pdbs = create_db_and_parallels(1000)\n",
    "private_results , true_results = query(db,noise=0.5)\n",
    "print(\"with noise:\" + str(private_results))\n",
    "print(\"withot noise:\" + str(true_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with noise:tensor(0.5038)\n",
      "withot noise:tensor(0.5076)\n"
     ]
    }
   ],
   "source": [
    "db, pdbs = create_db_and_parallels(10000)\n",
    "private_results , true_results = query(db,noise=0.5)\n",
    "print(\"with noise:\" + str(private_results))\n",
    "print(\"withot noise:\" + str(true_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The larger the dataset , the more noise you can add while getting an accurate result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with noise:tensor(0.5000)\n",
      "withot noise:tensor(0.5000)\n"
     ]
    }
   ],
   "source": [
    "db, pdbs = create_db_and_parallels(10000)\n",
    "private_results , true_results = query(db,noise=0.8)\n",
    "print(\"with noise:\" + str(private_results))\n",
    "print(\"withot noise:\" + str(true_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way this works is that the dp is very complex kind filter and the way that the dp filter works is that , it looks for insformation that is consistent across the multiple diffrent indivuals. It tries to filter out perferct dp , so no inoformation lekage would, in theory we can block out any information this is unique about participants in dataset and onlu let through information that is consistent across multiple different people. \n",
    "\n",
    "But it allows to look for repeating statistical information inside the dataset. \n",
    "* If we have a small dataset , odd of it finding the same stastical pattern twice.\n",
    "* if we have large dataset , it becomes easy to learn about patterns has you have more data points to look and compare with eachother to look for a similar statistical information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
