{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Local Differential Privacy**\n",
    "\n",
    "Local differential privacy is where given a collection of individuals, each individual adds noise to their data before sending it to the statistical database itself. \n",
    "So everything that gets into the database is already noised. So the protection is happening at the local level.\n",
    "\n",
    "**How much noise to add?** \n",
    "Well, it depends. Before that, you need to remember that differential privacy always requires a form of randomness or noise added to the query to protect from things like \"Differencing Attack \"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Project: Local Differential Privacy**\n",
    "As you can see, the basic sum query is not differentially private at all! In truth, differential privacy always requires a form of randomness added to the query. Let me show you what I mean.\n",
    "\n",
    "#### **Randomized Response (Local Differential Privacy)**\n",
    "\" Randomized Response is a technique that is used in social science when trying to learn about the high-level trends for taboo behavior. \" \n",
    "\n",
    "Let's say I have a group of people I wish to survey about a very taboo behavior which I think they will lie about (say, I want to know if they have ever committed a certain kind of crime). I'm not a policeman, I'm just trying to collect statistics to understand the higher level trend in society. So, how do we do this? One technique is to **add randomness to each person's response by giving each person the following instructions (assuming I'm asking a simple yes/no question):**\n",
    "\n",
    "* Flip a coin 2 times.\n",
    "* If the first coin flip is heads, answer honestly\n",
    "* If the first coin flip is tails, answer according to the second coin flip (heads for yes, tails for no)!\n",
    "\n",
    "Thus, each person is now protected with **\"plausible deniability\"**. If they answer \"Yes\" to the question \"have you committed X crime?\", then it might becasue they actually did, or it might be becasue they are answering according to a random coin flip. Each person has a high degree of protection. Furthermore, we can recover the underlying statistics with some accuracy, as the **\"true statistics\"** are simply **averaged with a 50% probability**. Thus, if we collect a bunch of samples and it turns out that 60% of people answer yes, then we know that the TRUE distribution is actually centered around 70%, because 70% averaged wtih 50% (a coin flip) is 60% which is the result we obtained.\n",
    "\n",
    "However, it should be noted that, especially when we only have a few samples, this comes at the **cost of accuracy**. This tradeoff **exists across all of Differential Privacy**. The greater the privacy protection (plausible deniability) the less accurate the results.\n",
    "\n",
    "Let's implement this local DP for our database before!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database\n",
    "\n",
    "import torch\n",
    "\n",
    "num_entries = 5000\n",
    "\n",
    "db = torch.rand(num_entries) > 0.5\n",
    "\n",
    "db\n",
    "\n",
    "# Create a function - To Remove Index\n",
    "def get_parallel_db(db, remove_index):\n",
    "    return torch.cat((db[0:remove_index],db[remove_index+1:]))\n",
    "\n",
    "# Create Function 2 to iterate through db and create parallel db\n",
    "\n",
    "def get_parallel_dbs(db):\n",
    "    parallel_dbs = list()\n",
    "    for i in range(len(db)):\n",
    "        pdb = get_parallel_db(db,i)\n",
    "        parallel_dbs.append(pdb)\n",
    "    return parallel_dbs\n",
    "\n",
    "# Function 3 to \n",
    "def create_db_and_parallels(num_entries):\n",
    "    db = torch.rand(num_entries) > 0.5\n",
    "    pdbs = get_parallel_dbs(db)\n",
    "    \n",
    "    return db, pdbs\n",
    "\n",
    "#function sensitivity\n",
    "def sensitivity(query, n_entries = 1000):\n",
    "    #Initialize a database of correct size and all parallel database\n",
    "    db , pdbs = create_db_and_parallels(n_entries)\n",
    "    full_db_result = query(db)\n",
    "    #Run the Query over all the databases\n",
    "    max_distance = 0 \n",
    "    for pdb in pdbs:\n",
    "        pdb_result = query(pdb)\n",
    "        # comapre paralled db and full db\n",
    "        db_distance = torch.abs(pdb_result - full_db_result)\n",
    "        if(db_distance > max_distance):\n",
    "            max_distance = db_distance\n",
    "    #Return the sensitivity\n",
    "    return max_distance\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4500)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_result = torch.mean(db.float())\n",
    "true_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "        1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1,\n",
       "        1, 1, 0, 0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# orginal local data or actual value from people\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db, pdbs = create_db_and_parallels(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0.,\n",
       "        1., 1., 0., 0., 1., 1., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First coin flip - will help determine whether we want to use the value its actually \n",
    "# going to database or to use the value that is randomly generated according to theis second\n",
    "# coin flip \n",
    "first_coin_flip = (torch.rand(len(db)) > 0.5).float()\n",
    "second_coin_flip = (torch.rand(len(db)) > 0.5).float()\n",
    "first_coin_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
       "        0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0.,\n",
       "        1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
       "        1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 1., 0., 0., 1., 1., 0., 1., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_coin_flip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this to create our noisy database or sythetic database or agumneted database. Half of the time , if the coin flip is one , we will use the database. So we can do this by **Multiplyting first coin flip by database** (first_coin_flip act like a mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
       "        1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "db.float() * first_coin_flip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some times we need to **lie**. WE need to choose randomly. SO if one minus our first coin flip . Below are all the places where we will actually choose randomly. So we can do this by simply samplying or multiplying times the second coin flip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "        1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1 - first_coin_flip) * second_coin_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEw augmented db , which is DP coombine this two\n",
    "augmented_db = (db.float() * first_coin_flip) + (1 - first_coin_flip) * second_coin_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4200)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remeber : Half of the value is always true\n",
    "# half of the value will always going to have a mean or try to have a mean of 0.5\n",
    "# so this will skew the putput of our query towards 0.5 , half the time we are using\n",
    "# second_coin_flip\n",
    "db_result = torch.mean(augmented_db.float()) * 2 - 0.5 #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pack all in the query\n",
    "def query(db):\n",
    "    true_result = torch.mean(db.float())\n",
    "    first_coin_flip = (torch.rand(len(db)) > 0.5).float()\n",
    "    second_coin_flip = (torch.rand(len(db)) > 0.5).float()\n",
    "    augmented_db = (db.float() * first_coin_flip) + (1 - first_coin_flip) * second_coin_flip\n",
    "    db_result = torch.mean(augmented_db.float()) * 2 - 0.5 \n",
    "    \n",
    "    return db_result, true_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with noise:tensor(0.7000)\n",
      "withot noise:tensor(0.4000)\n"
     ]
    }
   ],
   "source": [
    "db, pdbs = create_db_and_parallels(10)\n",
    "private_results , true_results = query(db)\n",
    "print(\"with noise:\" + str(private_results))\n",
    "print(\"withot noise:\" + str(true_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with noise:tensor(0.6800)\n",
      "withot noise:tensor(0.4800)\n"
     ]
    }
   ],
   "source": [
    "db, pdbs = create_db_and_parallels(100)\n",
    "private_results , true_results = query(db)\n",
    "print(\"with noise:\" + str(private_results))\n",
    "print(\"withot noise:\" + str(true_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with noise:tensor(0.4380)\n",
      "withot noise:tensor(0.4870)\n"
     ]
    }
   ],
   "source": [
    "db, pdbs = create_db_and_parallels(1000)\n",
    "private_results , true_results = query(db)\n",
    "print(\"with noise:\" + str(private_results))\n",
    "print(\"withot noise:\" + str(true_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remeber : Whenever we are adding noise to the distrubution , were corrupting it. So the statistics of the query are going to be sensitive to this noise . However , the more data points that we have, the more this noise will tend to average out. It will tend to not affect the output of the query because on average, across the large number of people, sometimes the noise is making the result higher than it should be or lower than the result shoulb be. But on an average, its actually still centered around the same mean of the true data distribution.\n",
    "\n",
    "Local DP is data hungry , In other to noise the dataset, you are adding a ton of noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
