{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Formal Definition of Diffrenetial Privacy**\n",
    "\n",
    "* Local DP\n",
    "* Differencing Attack\n",
    "* Basic queries\n",
    "* Sensitivity\n",
    "* Diffrenrial Privacy Definition\n",
    "\n",
    "Its a constraint so that you can analyze a query with noise and know wheather or not this query and noise is leaking too much of information.\n",
    "\n",
    "To measure threshold of leakeage \n",
    "1.  Epsilon \n",
    "2.  Delta\n",
    "\n",
    "\"Local Differentail Privacy\" because we added noise to each datapoint individually. This is necessary for some situations wherein the data is SO sensitive that individuals do not trust noise to be added later. However, it comes at a very high cost in terms of accuracy.\n",
    "\n",
    "However, alternatively we can add noise AFTER data has been aggregated by a function. In \"Global Differentail Privacy\" instead of adding noise to individua datapoint,it applies noise to the output of a function on datapoints.The advantage is that , in this kind of noise can allow for similar levels of protection with a lower affect on accuracy.\n",
    "\n",
    "However, participants must be able to trust that no-one looked at their datapoints before the aggregation took place. In some situations this works out well, in others (such as an individual hand-surveying a group of people), this is less realistic.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database\n",
    "\n",
    "import torch\n",
    "\n",
    "num_entries = 5000\n",
    "\n",
    "db = torch.rand(num_entries) > 0.5\n",
    "\n",
    "db\n",
    "\n",
    "# Create a function - To Remove Index\n",
    "def get_parallel_db(db, remove_index):\n",
    "    return torch.cat((db[0:remove_index],db[remove_index+1:]))\n",
    "\n",
    "# Create Function 2 to iterate through db and create parallel db\n",
    "\n",
    "def get_parallel_dbs(db):\n",
    "    parallel_dbs = list()\n",
    "    for i in range(len(db)):\n",
    "        pdb = get_parallel_db(db,i)\n",
    "        parallel_dbs.append(pdb)\n",
    "    return parallel_dbs\n",
    "\n",
    "# Function 3 to \n",
    "def create_db_and_parallels(num_entries):\n",
    "    db = torch.rand(num_entries) > 0.5\n",
    "    pdbs = get_parallel_dbs(db)\n",
    "    \n",
    "    return db, pdbs\n",
    "\n",
    "#function sensitivity\n",
    "def sensitivity(query, n_entries = 1000):\n",
    "    #Initialize a database of correct size and all parallel database\n",
    "    db , pdbs = create_db_and_parallels(n_entries)\n",
    "    full_db_result = query(db)\n",
    "    #Run the Query over all the databases\n",
    "    max_distance = 0 \n",
    "    for pdb in pdbs:\n",
    "        pdb_result = query(pdb)\n",
    "        # comapre paralled db and full db\n",
    "        db_distance = torch.abs(pdb_result - full_db_result)\n",
    "        if(db_distance > max_distance):\n",
    "            max_distance = db_distance\n",
    "    #Return the sensitivity\n",
    "    return max_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(73.0000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "db, pdbs = create_db_and_parallels(100)\n",
    "\n",
    "def query(db):\n",
    "    noise = 0.2\n",
    "    # Local Dp \n",
    "    return torch.sum(db.float() + noise)   \n",
    "   # return torch.sum(db.float())  + noise    # Global DP\n",
    "\n",
    "def M(db):\n",
    "    query(db) + noise\n",
    "\n",
    "query(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(43.2000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "db, pdbs = create_db_and_parallels(100)\n",
    "\n",
    "def query(db):\n",
    "    # Local Dp \n",
    "    # return torch.sum(db.float() + noise)\n",
    "    noise = 0.2\n",
    "    return torch.sum(db.float())  + noise    # Global DP\n",
    "\n",
    "def M(db):\n",
    "    query(db) + noise\n",
    "\n",
    "query(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the idea here is that we want to add noise to the output of our function. We actually have two different kinds of noise we can add \n",
    "- Laplacian Noise or \n",
    "- Gaussian Noise.\n",
    "\n",
    "However, before we do so at this point we need to dive into the formal definition of Differential Privacy.\n",
    "\n",
    "### Differential Privacy - A randomized algorithm $M$ with domain N |X| is (ε, δ)-differentially private if for all $S$ ⊆ Range($M$) and for all $x, y$ ∈ N |X| such that $∥x − y$∥1 ≤ 1: \n",
    "\n",
    "   **Pr[M(x) ∈ S] ≤ exp(ε) Pr[M(y) ∈ S] + δ**\n",
    "\n",
    "\"The Algorithmic Foundations of Differential Privacy\" - Cynthia Dwork and Aaron Roth - https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf\n",
    "\n",
    "This definition does not create differential privacy, instead it is a measure of how much privacy is afforded by a query $M$. Specifically, it's a comparison between running the query $M$ on a database $(x)$ and a parallel database $(y)$. As you remember, parallel databases are defined to be the same as a full database (x) with one entry/person removed.\n",
    "\n",
    "Thus, this definition says that FOR ALL parallel databases, the maximum distance between a query on database $(x)$ and the same query on database $(y)$ will be e^epsilon, but that occasionally this constraint won't hold with probability delta. Thus, this theorem is called \"epsilon delta\" differential privacy.\n",
    "\n",
    "#### How do we actually use epsilon and delta? \n",
    "\n",
    "We will see how to take a query and add **Randomized Mechanism**(A function with random noise added to its input , output and/or inner workings)\n",
    "\n",
    "#### **Epsilon**\n",
    "Let's unpack the intuition of this for a moment.\n",
    "\n",
    "Epsilon Zero: If a query satisfied this inequality where epsilon was set to 0, then that would mean that the query for all parallel databases outputed the exact same value as the full database. As you may remember, when we calculated the \"threshold\" function, often the Sensitivity was 0. In that case, the epsilon also happened to be zero.\n",
    "\n",
    "Epsilon One: If a query satisfied this inequality with epsilon 1, then the maximum distance between all queries would be 1 - or more precisely - the maximum distance between the two random distributions M(x) and M(y) is 1 (because all these queries have some amount of randomness in them, just like we observed in the last section).\n",
    "\n",
    "Delta\n",
    "Delta is basically the probability that epsilon breaks. Namely, sometimes the epsilon is different for some queries than it is for others. For example, you may remember when we were calculating the sensitivity of threshold, most of the time sensitivity was 0 but sometimes it was 1. Thus, we could calculate this as \"epsilon zero but non-zero delta\" which would say that epsilon is perfect except for some probability of the time when it's arbitrarily higher. Note that this expression doesn't represent the full tradeoff between epsilon and delta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **Lesson: How To Add Noise for Global Differential Privacy**\n",
    "In this lesson, we're going to learn about how to take a query and add varying amounts of noise so that it satisfies a certain degree of differential privacy. In particular, we're going to leave behind the Local Differential privacy previously discussed and instead opt to focus on Global differential privacy.\n",
    "\n",
    "So, to sum up, this lesson is about adding noise to the output of our query so that it satisfies a certain epsilon-delta differential privacy threshold.\n",
    "\n",
    "There are two kinds of noise we can add - Gaussian Noise or Laplacian Noise. Generally speaking Laplacian is better, but both are still valid. Now to the hard question...\n",
    "\n",
    "#### How much noise should we add to the query?\n",
    "The amount of noise necessary to add to the output is the query is a function of 4 things\n",
    "1.  Type of NOise (Gaussian/Laplacian) \n",
    "    - Here we will be using Laplacian\n",
    "2. Sensitivy of Query\n",
    "    - Sensitivity of the query that we are using to query the database.\n",
    "3. Desired Epsilon (ε)\n",
    "4. Desired Delta (δ)\n",
    "\n",
    "Thus, for each type of noise we're adding, we have different way of calculating how much to add as a function of sensitivity, epsilon, and delta. We're going to focus on Laplacian noise. \n",
    "\n",
    "Laplacian noise is increased/decreased according to a \"scale\" parameter b. We choose \"b\" based on the following formula.\n",
    "\n",
    "b = sensitivity(query) / epsilon\n",
    "\n",
    "**In other words, if we set b to be this value, then we know that we will have a privacy leakage of <= epsilon.** Furthermore, the nice thing about Laplace is that it guarantees this with delta == 0. There are some tunings where we can have very low epsilon where delta is non-zero, but we'll ignore them for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Querying Repeatedly\n",
    "if we query the database multiple times - we can simply add the epsilons (Even if we change the amount of noise and their epsilons are not the same)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project: Create a Differentially Private Query\n",
    "In this project, I want you to take what you learned in the previous lesson and \n",
    "* create a query function which sums over the database and \n",
    "* adds just the right amount of noise such that it satisfies an epsilon constraint.(use random.laplace ) \n",
    "* beta = sensitivity(query) / epsilon\n",
    "* Write a query for both \"sum\" and for \"mean\". Ensure that you use the correct sensitivity measures for both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epsilon = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "db, pdbs = create_db_and_parallels(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "        1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "        1, 1, 0, 0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_query(db):\n",
    "    return db.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplacian_mechanism(db, query, sensitivity):\n",
    "    \n",
    "    beta = sensitivity / epsilon\n",
    "    noise = torch.tensor(np.random.laplace(0, beta, 1))\n",
    "    \n",
    "    return query(db) + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(47)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_query(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-311.2988], dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laplacian_mechanism(db, sum_query, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for mean query\n",
    "def mean_query(db):\n",
    "    return torch.mean(db.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0630], dtype=torch.float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laplacian_mechanism(db, mean_query, 1/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
