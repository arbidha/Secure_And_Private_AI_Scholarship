{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks with PyTorch\n",
    "\n",
    "### Deep learning networks tend to be massive with dozens or hundreds of layers, that's where the term \"deep\" comes from. You can build one of these deep networks using only weight matrices as we did in the previous notebook, but in general it's very cumbersome and difficult to implement. PyTorch has a nice module nn that provides a nice way to efficiently build large neural networks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import helper\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to build a larger network that can solve a (formerly) difficult problem, identifying text in an image. Here we'll use the MNIST dataset which consists of greyscale handwritten digits. \n",
    "\n",
    "### Our goal is to build a neural network that can take one of these images and predict the digit in the image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to C:\\Users\\Arbidha/.pytorch/MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [00:06, 1599181.10it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Users\\Arbidha/.pytorch/MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to C:\\Users\\Arbidha/.pytorch/MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32768it [00:00, 267050.13it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Users\\Arbidha/.pytorch/MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to C:\\Users\\Arbidha/.pytorch/MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1654784it [00:01, 1370706.27it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Users\\Arbidha/.pytorch/MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to C:\\Users\\Arbidha/.pytorch/MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8192it [00:00, 96076.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Users\\Arbidha/.pytorch/MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "### Run this cell\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  training data loaded into trainloader\n",
    "* we make that an iterator with iter(trainloader)\n",
    "* This to loop through the dataset\n",
    "\n",
    "for image, label in trainloader:\n",
    "    ## do things with images and labels\n",
    "    \n",
    "* created the trainloader with a batch size of 64, and shuffle=True\n",
    "* batch size is the number of images we get in one iteration from the data loader and pass through our network, often called a batch.\n",
    "* shuffle=True tells it to shuffle the dataset every time we start going through the data loader again.\n",
    "\n",
    "### But here I'm just grabbing the first batch so we can check out the data. We can see below that images is just a tensor with size (64, 1, 28, 28). So, 64 images per batch, 1 color channel, and 28x28 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is what one of the images looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid dimensions for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-bc2cee0c0ad3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Greys_r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   2699\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2700\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[1;32m-> 2701\u001b[1;33m         None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2702\u001b[0m     \u001b[0msci\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2703\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1808\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1810\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5492\u001b[0m                               resample=resample, **kwargs)\n\u001b[0;32m   5493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5494\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5495\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5496\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    644\u001b[0m         if not (self._A.ndim == 2\n\u001b[0;32m    645\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m--> 646\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid dimensions for image data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid dimensions for image data"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAH4CAYAAADJr96jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAWJQAAFiUBSVIk8AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAHo9JREFUeJzt3X2QZlV9J/DvD9EsjDCAkVi1bIWFMAy1Ei2G8JJJDC9VE9atbChfklQCCm7+MJDFcvGPVLAKSUmsyiZIMFJ5qxGJiVbYKqU2MQkVRePCUsYxxF1reAnZIWTHiGKCOCK+cPaPe3ttmnmmT3ff7p6e+Xyqug5zz31+z3nONE9/5zzn3q7WWgAAFnPEeg8AANgYhAYAoIvQAAB0ERoAgC5CAwDQRWgAALoIDQBAF6EBAOgiNAAAXYQGAKCL0AAAdBEaAIAuQgMA0EVoAAC6TBIaqup1VfWeqvpUVX21qlpVfWCZtU6qqp1VtbeqnqmqPVV1c1UdP8VYAYDlOXKiOm9P8ookX0vyj0m2LqdIVZ2a5N4kJya5M8kDSc5J8pYkl1TV9tbaE5OMGABYkqk+nnhrki1Jjk3yCyuoc2uGwHBNa+3S1tovtdYuSvLuJKcnuXHFIwUAlqVaa9MWrLogyd1J/rC1dtkSHndKkkeS7Elyamvt2Xl9xyT5QpJKcmJrbd+UYwYAFncwbYS8aGzvmh8YkqS19lSSe5IcneS8tR4YAHBwhYbTx/ahGf0Pj+2WNRgLALDAVBshp7B5bJ+c0T93/LjFClXVrhldL8+wWXPPkkYGAAePk5N8tbX2b9f6iQ+m0LCYGtuVbMJ4wVFHHXXCGWecccIUAwKAtbZ79+48/fTT6/LcB1NomFtJ2Dyj/9gF583UWtu2v+NVteuMM844a9euWQsRAHBw27ZtWz772c/uWY/nPpj2NDw4trP2LJw2trP2PAAAq+hgCg13j+2OqnrOuMZLLrcneTrJfWs9MABgHUJDVb2wqraOd3/8/1prjyS5K8MGj6sXPOyGJJuS3O4eDQCwPibZ01BVlya5dPzjy8b2/Kq6bfzvL7fW3jb+979OsjvJoxkCwnxXZbiN9C1VdfF43rlJLszwscR1U4wXAFi6qTZCvjLJGxccO2X8SoaA8LYsorX2SFWdneRXklyS5NUZ7gR5S5IbWmtfmWi8AMASTRIaWmvvSPKOznP35LuXT+6v/7EkV04xLgBgOgfTRkgA4CAmNAAAXYQGAKCL0AAAdBEaAIAuQgMA0EVoAAC6CA0AQBehAQDoIjQAAF2EBgCgi9AAAHQRGgCALkIDANBFaAAAuggNAEAXoQEA6CI0AABdhAYAoIvQAAB0ERoAgC5CAwDQRWgAALoIDQBAF6EBAOgiNAAAXYQGAKCL0AAAdBEaAIAuQgMA0EVoAAC6CA0AQBehAQDoIjQAAF2EBgCgi9AAAHQRGgCALkIDANBFaAAAuggNAEAXoQEA6CI0AABdhAYAoIvQAAB0ERoAgC5CAwDQRWgAALoIDQBAF6EBAOgiNAAAXYQGAKCL0AAAdBEaAIAuQgMA0EVoAAC6CA0AQBehAQDoIjQAAF2EBgCgi9AAAHQRGgCALkIDANBFaAAAuggNAEAXoQEA6CI0AABdhAYAoIvQAAB0ERoAgC5CAwDQRWgAALoIDQBAl8lCQ1WdVFU7q2pvVT1TVXuq6uaqOn6JdX6kqu4cH/+NqvqHqvpoVV0y1VgBgKWbJDRU1alJdiW5Msmnk7w7yd8neUuS/1lVL+ms8wtJPpXk4rF9d5JPJvmxJH9WVddNMV4AYOmOnKjOrUlOTHJNa+09cwer6qYkb01yY5I3H6hAVb0wybuSfCPJttbag/P6fjXJ3yS5rqp+vbX2zETjBgA6rXiloapOSbIjyZ4k713QfX2SfUkur6pNi5Q6IcnmJA/NDwxJ0lrbneShJEclefFKxwwALN0UH09cNLZ3tdaend/RWnsqyT1Jjk5y3iJ1Hk/ypSRbquq0+R1VtSXJaUnub609McGYAYAlmiI0nD62D83of3hstxyoSGutJbl6HNOuqnp/Vb2rqm7PsF/i80leP8F4AYBlmGJPw+axfXJG/9zx4xYr1Fq7o6r2JvlgkjfM6/pikvdl2Fy5qKraNaNra8/jAYDnW4v7NNTYtkVPrLosyV9muHLijAwfa5yR5GNJfivJh1ZpjADAIqZYaZhbSdg8o//YBeft17hvYWeSzyW5fN7+iAeq6vIMH4O8vqouaK194kC1WmvbZjzHriRnHeixAMD+TbHSMHelw6w9C3ObGmfteZizI8kLk3xyPxsqn03yV+Mf9xsIAIDVNUVouHtsd1TVc+pV1TFJtid5Osl9i9T5nrF96Yz+uePfXM4gAYCVWXFoaK09kuSuJCdnuPphvhuSbEpye2tt39zBqtpaVQs3JX5qbF9XVT84v6OqXpnkdRn2RXx8pWMGAJZuqjtCXpXk3iS3VNXFSXYnOTfJhRk+llh4++fdYzu3STKttU9X1fsy3Ir6r6vqw0kezRBGLk3yoiQ3t9Y+P9GYAYAlmCQ0tNYeqaqzk/xKkkuSvDrJF5LckuSG1tpXOkv9pwx7F65I8uNJjkny1ST/I8nvtdZcPQEA62SqlYa01h7LsErQc27NON6S3DZ+AQAHkbW4TwMAcAgQGgCALkIDANBFaAAAuggNAEAXoQEA6CI0AABdhAYAoIvQAAB0ERoAgC5CAwDQRWgAALoIDQBAF6EBAOgiNAAAXYQGAKCL0AAAdBEaAIAuQgMA0EVoAAC6CA0AQBehAQDoIjQAAF2EBgCgi9AAAHQRGgCALkIDANBFaAAAuggNAEAXoQEA6CI0AABdhAYAoIvQAAB0ERoAgC5CAwDQRWgAALoIDQBAF6EBAOgiNAAAXYQGAKCL0AAAdBEaAIAuQgMA0EVoAAC6CA0AQBehAQDoIjQAAF2EBgCgi9AAAHQRGgCALkIDANBFaAAAuggNAEAXoQEA6CI0AABdhAYAoIvQAAB0ERoAgC5CAwDQRWgAALoIDQBAF6EBAOgiNAAAXYQGAKCL0AAAdBEaAIAuQgMA0EVoAAC6CA0AQBehAQDoIjQAAF2EBgCgy2ShoapOqqqdVbW3qp6pqj1VdXNVHb+MWmdW1e1V9dhY6/Gq+mRVvWGq8QIAS3PkFEWq6tQk9yY5McmdSR5Ick6StyS5pKq2t9ae6Kx1RZLfT/L1JH+SZE+S45K8PMmrk9w+xZgBgKWZJDQkuTVDYLimtfaeuYNVdVOStya5McmbFytSVedlCAz/O8klrbV/WtD/wonGCwAs0Yo/nqiqU5LsyLAi8N4F3dcn2Zfk8qra1FHu15K8IMllCwNDkrTWvrWy0QIAyzXFSsNFY3tXa+3Z+R2ttaeq6p4MoeK8JB+bVaSqTkryo0k+k+TzVXVhkm1JWpL7k9y9sD4AsHamCA2nj+1DM/ofzhAatuQAoSHJD807/+NJLljQ/7+q6jWttb9b5jgBgBWYIjRsHtsnZ/TPHT9ukTonju1PJflyktdkCBkvzfAxx+VJ/rSqzmytffNAhapq14yurYuMAQCYYS3u01Bj2xY57wXz2p9vrX24tfbV1tojSd6Y4WOLLUleuzrDBAAOZIqVhrmVhM0z+o9dcN4s/zy2zyT56PyO1lqrqjuTnJ3hUs4PHqhQa23b/o6PKxBnLTIOAGA/plhpeHBst8zoP21sZ+15WFjnqRkbHudCxVFLGBsAMJEpQsPdY7ujqp5Tr6qOSbI9ydNJ7lukzucy7GX43qr6vv30v3xs9yx/qADAcq04NIx7Du5KcnKSqxd035BkU5LbW2v75g5W1daqes6mxNbat5P8zvjHX5sfQKrqzCRXJPl2kv+20jEDAEs31R0hr8pwG+lbquriJLuTnJvkwgwfS1y34PzdY1sLjv9qkouTvCHJmVX1iQxXT7w2yb9Kcq1LLgFgfUxy9cS42nB2ktsyhIVrk5ya5JYk5/f+3onW2tczhIYbkhydYeXiP2YIJK9urd00xXgBgKWbaqUhrbXHklzZee7CFYb5fV9P8o7xCwA4SKzFfRoAgEOA0AAAdBEaAIAuQgMA0EVoAAC6CA0AQBehAQDoIjQAAF2EBgCgi9AAAHQRGgCALkIDANBFaAAAuggNAEAXoQEA6CI0AABdhAYAoIvQAAB0ERoAgC5CAwDQRWgAALoIDQBAF6EBAOgiNAAAXYQGAKCL0AAAdBEaAIAuQgMA0EVoAAC6CA0AQBehAQDoIjQAAF2EBgCgi9AAAHQRGgCALkIDANBFaAAAuggNAEAXoQEA6CI0AABdhAYAoIvQAAB0ERoAgC5CAwDQRWgAALoIDQBAF6EBAOgiNAAAXYQGAKCL0AAAdBEaAIAuQgMA0EVoAAC6CA0AQBehAQDoIjQAAF2EBgCgi9AAAHQRGgCALkIDANBFaAAAuggNAEAXoQEA6CI0AABdhAYAoIvQAAB0ERoAgC5CAwDQRWgAALoIDQBAF6EBAOgiNAAAXSYLDVV1UlXtrKq9VfVMVe2pqpur6vgV1HxVVX2nqlpVvXOqsQIAS3fkFEWq6tQk9yY5McmdSR5Ick6StyS5pKq2t9aeWGLNY5K8P8nXk7x4inECAMs31UrDrRkCwzWttUtba7/UWrsoybuTnJ7kxmXU/M0km5O8a6IxAgArsOLQUFWnJNmRZE+S9y7ovj7JviSXV9WmJdT8ySRXJrkmyd6VjhEAWLkpVhouGtu7WmvPzu9orT2V5J4kRyc5r6dYVZ2Y5PeSfKS19oEJxgcATGCK0HD62D40o//hsd3SWe93M4zrzSsZFAAwrSk2Qm4e2ydn9M8dP26xQlX1piQ/meSnW2tfXO6AqmrXjK6ty60JAIe7tbhPQ41tO+BJVScnuTnJHa21P17lMQEASzTFSsPcSsLmGf3HLjhvlp1Jnk5y1UoH1Frbtr/j4wrEWSutDwCHoylWGh4c21l7Fk4b21l7HuacleGyzS+NN3NqVdWSvG/sv2489pGVDRcAWI4pVhruHtsdVXXE/Csoxhs0bc+wgnDfInVuz3CVxUKnJXlVkvuT7EryNyseMQCwZCsODa21R6rqrgz3arg6yXvmdd+QZFOS32mt7Zs7WFVbx8c+MK/ONfurX1VXZAgNf9pae/tKxwsALM8kt5HOsA/h3iS3VNXFSXYnOTfJhRk+lrhuwfm7x7YCAGwIk1w90Vp7JMnZSW7LEBauTXJqkluSnL/U3zsBABx8plppSGvtsQy3fu45t3uFobV2W4YwAgCso7W4TwMAcAgQGgCALkIDANBFaAAAuggNAEAXoQEA6CI0AABdhAYAoIvQAAB0ERoAgC5CAwDQRWgAALoIDQBAF6EBAOgiNAAAXYQGAKCL0AAAdBEaAIAuQgMA0EVoAAC6CA0AQBehAQDoIjQAAF2EBgCgi9AAAHQRGgCALkIDANBFaAAAuggNAEAXoQEA6CI0AABdhAYAoIvQAAB0ERoAgC5CAwDQRWgAALoIDQBAF6EBAOgiNAAAXYQGAKCL0AAAdBEaAIAuQgMA0EVoAAC6CA0AQBehAQDoIjQAAF2EBgCgi9AAAHQRGgCALkIDANBFaAAAuggNAEAXoQEA6CI0AABdhAYAoIvQAAB0ERoAgC5CAwDQRWgAALoIDQBAF6EBAOgiNAAAXYQGAKCL0AAAdBEaAIAuQgMA0EVoAAC6CA0AQBehAQDoIjQAAF2EBgCgy2ShoapOqqqdVbW3qp6pqj1VdXNVHd/5+E1V9XNV9UdV9UBV7auqp6rqM1V1bVW9aKqxAgBLd+QURarq1CT3JjkxyZ1JHkhyTpK3JLmkqra31p5YpMyPJvlAkq8kuTvJR5KckOQnkvx6ktdU1cWttW9MMWYAYGkmCQ1Jbs0QGK5prb1n7mBV3ZTkrUluTPLmRWr8U5LLktzRWvvmvBrHJPlEkh9OcnWS35hozADAEqz444mqOiXJjiR7krx3Qff1SfYlubyqNh2oTmvt/tbaH84PDOPxp/LdoHDBSscLACzPFHsaLhrbu1prz87vGH/g35Pk6CTnreA5vjW2315BDQBgBaYIDaeP7UMz+h8e2y0reI43je2fr6AGALACU+xp2Dy2T87onzt+3HKKV9UvJrkkyf1JdnY+ZteMrq3LGQMAsDb3aaixbUt+YNVrktycYZPka1tr31rkIQDAKplipWFuJWHzjP5jF5zXpaouTfKhJI8nubC19ve9j22tbZtRc1eSs5YyDgBgMMVKw4NjO2vPwmljO2vPw/NU1euT3JHki0l+rLX24CIPAQBW2RSh4e6x3VFVz6k33mNhe5Knk9zXU6yqfjbJB5PszRAYHl7kIQDAGlhxaGitPZLkriQnZ7j50nw3JNmU5PbW2r65g1W1taqetymxqt6Y5A+S/EOSVy3lIwkAYHVNdUfIqzLcRvqWqro4ye4k5ya5MMPHEtctOH/32M5tkkxVXZjh6ogjMqxeXFlVCx6Wf2mt3TzRmAGAJZgkNLTWHqmqs5P8SobLI1+d5AtJbklyQ2vtKx1lvj/fXfl404xzHs1wNQUAsMamWmlIa+2xJFd2nvu8JYTW2m1JbptqPADAtNbiPg0AwCFAaAAAuggNAEAXoQEA6CI0AABdhAYAoIvQAAB0ERoAgC5CAwDQRWgAALoIDQBAF6EBAOgiNAAAXYQGAKCL0AAAdBEaAIAuQgMA0EVoAAC6CA0AQBehAQDoIjQAAF2EBgCgi9AAAHQRGgCALkIDANBFaAAAuggNAEAXoQEA6CI0AABdhAYAoIvQAAB0ERoAgC5CAwDQRWgAALoIDQBAF6EBAOgiNAAAXYQGAKCL0AAAdBEaAIAuQgMA0EVoAAC6CA0AQBehAQDoIjQAAF2EBgCgi9AAAHQRGgCALkIDANBFaAAAuggNAEAXoQEA6CI0AABdhAYAoIvQAAB0ERoAgC5CAwDQRWgAALoIDQBAF6EBAOgiNAAAXYQGAKCL0AAAdBEaAIAuQgMA0EVoAAC6CA0AQBehAQDoIjQAAF2EBgCgi9AAAHQRGgCALpOFhqo6qap2VtXeqnqmqvZU1c1VdfwS65wwPm7PWGfvWPekqcYKACzdkVMUqapTk9yb5MQkdyZ5IMk5Sd6S5JKq2t5ae6KjzkvGOluSfDzJh5JsTXJlkv9QVee31v5+ijEDAEsz1UrDrRkCwzWttUtba7/UWrsoybuTnJ7kxs46v5ohMLy7tXbxWOfSDOHjxPF5AIB1sOLQUFWnJNmRZE+S9y7ovj7JviSXV9WmRepsSnL5eP71C7p/a6z/4+PzAQBrbIqVhovG9q7W2rPzO1prTyW5J8nRSc5bpM75SY5Kcs/4uPl1nk1y1/jHC1c8YgBgyaYIDaeP7UMz+h8e2y1rVAcAWAVTbITcPLZPzuifO37cGtVJVe2a0fWK3bt3Z9u2bYuVAICD0u7du5Pk5PV47kmunlhEjW07COoc8fTTT3/ns5/97N+ucCw839axfWBdR3FoMrerx9yuHnO7el6R5MXr8cRThIa5FYDNM/qPXXDeatdJa22/SwlzKxCz+lk+c7t6zO3qMberx9yungOspq+6KfY0PDi2s/YanDa2s/YqTF0HAFgFU4SGu8d2R1U9p15VHZNke5Knk9y3SJ37xvO2j4+bX+eIDJd1zn8+AGANrTg0tNYeyXA55MlJrl7QfUOSTUlub63tmztYVVurauv8E1trX0vyB+P571hQ5xfH+n/hjpAAsD6m2gh5VYbbP99SVRcn2Z3k3Az3VHgoyXULzt89trXg+C8nuSDJf6mqVyb5dJIzkvxkksfz/FACAKyRSW4jPa42nJ3ktgxh4dokpya5Jcn5Pb93YqzzRIabPN2S5AfGOucmeV+SbePzAADroFpb6ZWQAMDhYLJfjQ0AHNqEBgCgi9AAAHQRGgCALkIDANBFaAAAuggNAECXDR8aquqkqtpZVXur6pmq2lNVN1fV8Uusc8L4uD1jnb1j3ZNWa+wHu5XObVVtqqqfq6o/qqoHqmpfVT1VVZ+pqmur6kWr/RoOVlN93y6o+aqq+k5Vtap655Tj3UimnNuqOrOqbq+qx8Zaj1fVJ6vqDasx9oPdhO+3P1JVd46P/0ZV/UNVfbSqLlmtsR/Mqup1VfWeqvpUVX11/H/4A8usNfl7y3Pqb+SbO1XVqRluX31ikjsz/N72czLcvvrBJNt77kZZVS8Z62xJ8vEkf53hd8HP3b76/MPtd15MMbfjG8CfJflKhl809ndJTkjyE0leNta/uLX2jVV6GQelqb5vF9Q8JsnnknxvkhcnubG19vYpx70RTDm3VXVFkt9P8vUkf5JkT5Ljkrw8yd7W2s9MPPyD2oTvt7+Q5NYk+5J8OMk/JjkpyWuSHJ3k7a21G1fjNRysqur+JK9I8rUM87E1yR+21i5bYp3J31uep7W2Yb+S/EWSluQ/Lzh+03j8tzvr/M54/k0Ljl8zHv/z9X6tG3Fuk7wyyc8ledGC48ck2TXWuXa9X+tGnNv91NyZIZz98ljjnev9Ojfy3CY5L8m3k9yf5GX76X/her/WjTi3SV6Y5F8y/Ebj0xf0nZHkGxlC2ves9+td47m9MMlpGX4f0wXjfH5gPf6OFn2O9Z6sFUzyKeMk/J8kRyzoOyZDYtuXZNMidTaN36RfS3LMgr4jxvotySnr/Zo32twu8hw/Oz7Hf1/v17vR5zbDilhLclmSKw7X0DDl3Cb5q7HWy9f7dR0MXxO+337fWOdvZ/R/bux/yXq/5nWc62WFhrV4326tbeg9DReN7V2ttWfnd7TWnkpyT4alrvMWqXN+kqOS3DM+bn6dZzP82u9kSIKHi6nm9kC+NbbfXkGNjWjSua2qE5P8XpKPtNaW9RnoIWSSuR33Mf1oks8k+XxVXVhVbxv34VxcVRv5fXO5pvq+fTzJl5JsqarT5ndU1ZYM/9q+v610Cf3wtBbv2xs6NJw+tg/N6H94bLesUZ1DyVrMyZvG9s9XUGMjmnpufzfD/8dvXsmgDhFTze0PzTv/4+PXf03y60n+Msn9VfUDKxjnRjTJ3Lbhn71XZ/ie3VVV76+qd1XV7Rk+svx8ktdPMN7D0Zr8LDtyJQ9eZ5vH9skZ/XPHj1ujOoeSVZ2TqvrFJJdk+Lx453JqbGCTzW1VvSnDRxM/3Vr74gRj2+immtsTx/anknw5wwa9jyV5aZLrk1ye5E+r6szW2jeXP9wNZbLv29baHVW1N8kHk8y/CuWLSd6X5LDadD6hNflZtpFXGhZTY7vSy0OmqnMoWfacVNVrktyc5J+SvLa19q1FHnK46Zrbqjo5wzze0Vr741Ue06Gi9/v2BfPan2+tfbi19tXW2iNJ3pjhY4stSV67OsPckLrfE6rqsgwrNp/KsPnx6LH9WJLfSvKhVRrj4W6Sn2UbOTTMpabNM/qPXXDeatc5lKzKnFTVpRneEB5PckE7zC5jHU01tzsz7EC/aopBHSKmmtt/Httnknx0fse4vH7n+MdzljrADWySuR33LezM8DHE5a21B1prT7fWHsiwgrMryeur6oKVD/mwsyY/yzZyaHhwbGd9PjO3yWbW5ztT1zmUTD4nVfX6JHdkWIL8sdbag4s85FA11dyelWEZ/UvjjWBaVbUMy7tJct147CMrG+6GMvV7wlMLN5SN5kLFUUsY20Y31dzuyHDZ5Sf3s1nv2QxXrSTJtuUM8jC3Jj/LNvKehrvHdkdVHTH/G3C80c32DP8Su2+ROveN522vqmPmX0Ex7pLeseD5DgdTze3cY342ye1J/m+SCw/TFYY5U83t7RmWdRc6LcmrMuwX2ZXkb1Y84o1jqrn9XIa9DN9bVd+3n/0iLx/bPSsf8oYx1dx+z9i+dEb/3PHDZa/IlCZ9355pva9JXeH1rEu6kUWGu2xt3U+duZs7/caC427utPK5fWOS72TY3PT96/26DoavqeZ2Ru0rcpjep2HKuU3yzvH892feNe9JzszwxvutJD+w3q93o81tho90WoZ74/zggr5XjnP7bJJ/t96vdx3n+YIc4D4NGVZqtiY5daV/R8v5OtRuI707ybkZ7qnwUJIfbvOu9x2Xb9NaqwV1Ft5G+tMZNubM3Ub6h9uwCeqwMcXcVtWFGTY8HZHhc8zH9vNU/9Jau3mVXsZBaarv2xm1r8jwEYXbSK/sPeHoDBvzzsuwWvOJDP8Kfm2GjyWuba3dtMov56Ay4dzuTHJlhtWEDyd5NMnJSS5N8qIkN7fW3rrKL+egMu73unT848uS/HiGf2h9ajz25dba28ZzT85wA6dHW2snL6izpL+jZVnvVDVBKvs3Gd4kv5Dhm/DRJL+Z5IT9nNsy7mXaT98J4+MeHet8IcMPupPW+zVu1LnNd//Ve6CvPev9Ojfi3B6g7tycH5YrDVPObYaPf96R4f79z2TYQPaXSf79er/GjTy3GXbxX5EhiP1zhhu8fSVDSPuZ9X6N6zSv7+h9n8wQsGa+dy7l72g5Xxt6pQEAWDsb+eoJAGANCQ0AQBehAQDoIjQAAF2EBgCgi9AAAHQRGgCALkIDANBFaAAAuggNAEAXoQEA6CI0AABdhAYAoIvQAAB0ERoAgC5CAwDQRWgAALr8P6PB9XeCHffNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 252,
       "width": 262
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   The networks you've seen so far are called fully-connected or dense networks. Each unit in one layer is connected to each unit in the next layer.In fully-connected networks, the input to each layer must be a one-dimensional vector (which can be stacked into a 2D tensor as a batch of multiple examples).\n",
    "\n",
    "*   However, our images are 28x28 2D tensors, so we need to convert them into 1D vectors. Thinking about sizes, we need to convert the batch of images with shape (64, 1, 28, 28) to a have a shape of (64, 784), 784 is 28 times 28. This is typically called flattening, we flattened the 2D images into 1D vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OUR GOAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we need 10 output units, one for each digit. We want our network to predict the digit shown in an image, so what we'll do is calculate probabilities that the image is of any one digit or class. This ends up being a discrete probability distribution over the classes (digits) that tells us the most likely class for the image. That means we need 10 output units for the 10 classes (digits). We'll see how to convert the network output into a probability distribution next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: \n",
    "### Flatten the batch of images images. Then build a multi-layer network with 784 input units, 256 hidden units, and 10 output units using random tensors for the weights and biases. For now, use a sigmoid activation for the hidden layer. Leave the output layer without an activation, we'll add one that gives us a probability distribution next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        ...,\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.]])\n",
      "tensor([[ -3.6636, -10.2372,   6.6623, -11.6412,  -0.3391,  -7.2024,  -8.0738,\n",
      "          12.5667,   4.9425,   5.4034],\n",
      "        [  1.9316,  -7.3693,  12.2230,  -5.1341,   4.8626, -12.0173, -16.8580,\n",
      "           6.5903,   2.6282,  -7.9222],\n",
      "        [ -5.6430, -17.9577,   4.5458,   0.6003,   7.8570,  -7.6020,  -1.7694,\n",
      "           3.7084,  15.5935,  -0.6830],\n",
      "        [ -8.6005, -12.3773,   4.6897,  18.8306,   0.6668,  -9.1522,  -6.2259,\n",
      "          18.3098,   7.9675,  11.4519],\n",
      "        [  3.7715,  -7.3679,   5.5727,   2.8102,   8.4232,  -3.7337,  -8.9310,\n",
      "           6.1208,  11.8703,   5.3602],\n",
      "        [  8.6161,  -9.3104,   6.3886,   1.9412,  16.3784,  -9.1794, -18.5110,\n",
      "           3.4504,  11.1045,  -4.3428],\n",
      "        [ 14.7109,  -0.1841,   7.1370,  -1.0514,   0.6625,  -1.6055, -19.3965,\n",
      "           6.4986,   5.2779,  -1.8926],\n",
      "        [  0.8267,  -9.5284,   5.6063,   6.8779,   4.4574,   1.4539, -12.5726,\n",
      "           7.9165,   2.1676,   5.0944],\n",
      "        [ -0.9160,  -2.3076,  11.8331,  -0.8117,  13.8758,   1.9260,  -5.1007,\n",
      "           5.5268,  12.0162, -11.8777],\n",
      "        [  7.6384,   0.4733,   4.9818,  -6.5565,   7.8033,  -1.4954, -12.9347,\n",
      "           4.4215,   8.2433,  -2.0507],\n",
      "        [  2.8523,  -8.5771,   1.7183,  12.7013,   9.4574,  -5.2281,  -6.9128,\n",
      "          -4.3692,  17.7925,   9.9642],\n",
      "        [  2.3544,  -3.4679,   9.7568,  -7.9133,  10.5332,  -3.9837, -11.2380,\n",
      "          -3.6103,   7.5862,   5.0770],\n",
      "        [ -1.9285, -19.2293,  -0.9577,  -3.3858,  14.4780,  -9.1309,  -8.9115,\n",
      "          15.0278,  17.1966,  -0.8856],\n",
      "        [ 10.7196,  -4.2253,  12.7680,  -1.9388,   9.2479,   0.5497, -13.0742,\n",
      "           4.1635,   9.4050,  -5.4074],\n",
      "        [  1.1679,  -8.6252,  12.8294,  -6.2813,  10.9090, -13.2566,  -4.3641,\n",
      "           1.0395,   1.6301,  15.4897],\n",
      "        [ -1.7901, -15.1651,   0.6523,   1.9686,  17.9803,  -2.7159, -13.3258,\n",
      "           1.5466,  11.3037,   3.1572],\n",
      "        [  4.4840,  -6.2904,  14.9093,   8.1653,   3.1960,  -4.4654, -12.2558,\n",
      "           6.2114,  10.2869,  -3.1848],\n",
      "        [  0.2559, -10.5802,  11.6118,  -3.2028,  -6.2863, -10.7562, -14.4299,\n",
      "           5.9937,  -1.3695,  -1.5343],\n",
      "        [  1.4855, -15.6556,   2.6350,   9.1670,  16.3758,  -2.8014,  -8.2505,\n",
      "          -0.2872,   5.3312,   0.8669],\n",
      "        [ -1.8825, -10.2072,  11.0977,  -1.4017,   5.0858,  -1.8959, -20.2059,\n",
      "           4.5993,   7.7508,  -2.0997],\n",
      "        [  2.8771,  -2.5504,   6.4396,   4.2312,  14.0777, -10.1818, -10.2793,\n",
      "           3.9946,  14.3874,   9.1203],\n",
      "        [  7.6537,  -9.7197,   0.0564,   6.2865,   4.4336,  -8.1169,  -7.0496,\n",
      "           5.0477,   4.4688,   7.3566],\n",
      "        [  9.5187, -13.7348,   6.1663,   8.6398,  -3.0375, -11.5712,  -9.2552,\n",
      "          -0.2586,   8.2876,  13.6097],\n",
      "        [ -1.2208,  -7.6104,   3.9050,  11.7570,  10.5862,  -0.6446,  -2.0480,\n",
      "           8.8779,  -1.6275,   7.5705],\n",
      "        [  5.5584,  -9.4757,   1.3220,  -6.8021,   4.6115,  -9.7260, -16.3966,\n",
      "          -2.5817,   8.5279,  -2.2901],\n",
      "        [  6.8854,   0.6309,  -1.8553,  -4.3851,  -0.2485,  -0.3262, -20.2784,\n",
      "          -1.0455,   5.8892,  -9.4678],\n",
      "        [ -5.2696, -10.1111,  11.1885,   5.1083,   5.3749,  -2.4761,  -4.0289,\n",
      "           5.9908,   9.9363,  13.8672],\n",
      "        [ -1.1851,  -5.3556,   7.5228,  13.0506,  10.6331,  -8.7600,  -9.5728,\n",
      "          10.3272,  10.6295,  -0.9176],\n",
      "        [  1.9390,  -8.8316,  10.4459,  10.2409,  18.0392, -10.0484, -14.2051,\n",
      "           5.2345,   4.5508, -10.5692],\n",
      "        [ -5.6761,  -3.9506,  12.8173,  -3.4684,   6.1693,  -5.7847,  -7.7008,\n",
      "           5.8656,   2.4386,   5.7516],\n",
      "        [ -6.2858,  -8.8615,  12.3333,  -3.2250,   5.7175,  -2.4524,  -5.5207,\n",
      "           9.1764,   6.4800,  -1.2374],\n",
      "        [  7.0390, -13.1029,   8.8944,  -0.6228,  14.3158,  -0.7996, -11.8074,\n",
      "           7.4573,  17.4157,   2.6474],\n",
      "        [  9.1804,   2.3969,   7.0710,  -9.3779,  -1.1187,  -4.0833, -11.5022,\n",
      "           5.3603,   5.2711,  -0.8809],\n",
      "        [  1.6367,  -5.6846,  13.1435,   0.3187,  15.0106,  -8.5503,  -7.6141,\n",
      "          -2.6511,   4.2995,  11.0549],\n",
      "        [ -3.2279,  -0.4334,  11.5359,  -2.3016,   8.1100,  -6.5297,  -3.2697,\n",
      "          -2.0291,  -0.2128,   8.6594],\n",
      "        [  2.4026,  -7.2845,  12.4560,  -2.7538,   6.0560,  -4.7094, -15.5213,\n",
      "           5.7171,  11.5249,  -7.8341],\n",
      "        [  6.8454,  -8.2812,   8.0292,   9.2307,   6.5563,  -8.5726,  -7.4527,\n",
      "           6.1817,   1.0346,   1.1082],\n",
      "        [  3.2027, -10.4398,  14.9259,  -0.8626,  12.0151,  -3.2358, -11.7183,\n",
      "           5.3463,  17.2366,   2.9855],\n",
      "        [  7.3166,  -2.1920,   3.6783, -11.9928,   6.3425, -14.5222, -19.3449,\n",
      "           1.6788,  -2.1346,   5.5941],\n",
      "        [ 16.0183,  -6.9215,   1.1463,  -7.7462,   8.6164,   3.5279,  -1.4922,\n",
      "           1.0188,   5.2381,   7.7875],\n",
      "        [  1.5158, -11.8786,   4.7602,   4.4053,   5.1087, -10.0328,  -7.1047,\n",
      "           0.4477,  13.2072,  -6.9353],\n",
      "        [  4.7538,  -7.7100,   1.4629,   0.7377,   4.1745, -12.5938, -14.7259,\n",
      "           4.2751,  10.6157,  -1.2405],\n",
      "        [ -2.3833, -13.0030,   0.5915,   3.6583,   9.1721,   0.0411,  -0.3470,\n",
      "           7.1382,   5.2204,   3.2641],\n",
      "        [  6.8616,   7.7505,  16.4256,   0.8565,   8.2250,  -4.3518, -10.6228,\n",
      "          -3.5906,   0.5666,   2.2934],\n",
      "        [ -0.1624, -17.7890,  -1.3018,  -8.7879,   9.1166, -11.1316,  -7.0459,\n",
      "           0.1014,  11.3642,  -0.3535],\n",
      "        [  4.1575, -12.0429,   4.4990,  10.3910,  11.5061,  -4.6440, -12.4542,\n",
      "           9.8371,  16.9047,   3.4328],\n",
      "        [  9.0991,  -9.0350,  -0.0351,  10.3289,  11.8521,  -3.8783, -10.6803,\n",
      "          11.0488,  13.2889,  -4.1674],\n",
      "        [  0.4666,  -4.2205,  11.3227,   4.9977,   1.2086,  -6.6835,  -5.3842,\n",
      "          -7.0897,  13.7964,   9.8103],\n",
      "        [  9.9745,   2.8756,  15.9811,  -3.8761,   5.4494,  -0.1038, -13.0100,\n",
      "          -5.9774,   3.0147,  11.5518],\n",
      "        [  9.6902,  -8.2690,  13.0821,   3.0849,   8.2013,  -4.9416, -10.2313,\n",
      "           8.3833,   0.7513,   3.9988],\n",
      "        [  5.0414,   3.7094,  14.7733,   1.9470,   6.5853, -10.7717, -10.3231,\n",
      "          -6.2104,   2.5848,   2.0353],\n",
      "        [  5.8859, -10.3619,  13.7190,   6.9292,  10.2839,  -5.6206,  -7.2507,\n",
      "           1.3939,   6.9363,   2.9653],\n",
      "        [  9.5762, -16.9530,   6.7373,  -0.5977,  11.9273,  -6.5067,  -9.5647,\n",
      "           9.2387,  16.7657,   4.7175],\n",
      "        [  6.0651,  -1.1043,   9.6700,   1.2440,   8.5327,  -5.6561, -17.8832,\n",
      "          -4.8444,  -0.3928,  -4.3848],\n",
      "        [  3.0033,   0.1666,  19.1551,  -3.2865,  15.8770,  -5.8343, -10.7870,\n",
      "           0.6386,  12.8964,   9.6247],\n",
      "        [  2.3009, -12.6727,   7.6813,   6.2972,  13.2530,  -7.8533, -16.2809,\n",
      "           5.4459,  19.8899,   1.8146],\n",
      "        [  2.0102,  -9.6595,   5.2786,  -1.7055,  -0.7363,  -4.8894, -11.8634,\n",
      "          12.7383,   9.0078,   0.5778],\n",
      "        [  1.7764, -16.7616,  11.0563,   3.9646,   5.7191,  -6.6813,  -9.8782,\n",
      "           0.7709,   8.8436,   3.5613],\n",
      "        [  6.4390,  -8.1356,   9.1517,   6.6186,  11.5203,   0.7261, -11.5413,\n",
      "          -1.3059,  12.6868,  -1.2032],\n",
      "        [ -7.1774,  -4.1161,   8.9964,   1.1559,   5.4209, -11.3155,  -8.7859,\n",
      "           5.8572,   3.0303,   4.4743],\n",
      "        [ -0.0294,   1.3760,  12.2506,  -0.1426,  11.1876,   1.0042, -12.6002,\n",
      "           1.3816,  10.2109, -10.1497],\n",
      "        [  1.5247, -14.3158,  12.6330,  -1.2369,  10.7106,  -5.5046,   0.7291,\n",
      "           4.0527,   9.7276,   4.8563],\n",
      "        [ -3.1398,  -9.7111,   0.8444,   2.9261,   0.6832,  -7.5597, -12.3017,\n",
      "           8.6350,   5.5552,  -3.0726],\n",
      "        [ -2.3831, -11.2571,   9.9553,  -5.7673,  12.0583,   1.0111,  -4.0222,\n",
      "           4.8769,   4.9661,   3.4358]])\n"
     ]
    }
   ],
   "source": [
    "## Your solution\n",
    "def activation(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "# Flatten the batch of images\n",
    "inputs = images.view(images.shape[0], -1)\n",
    "print(inputs)\n",
    "\n",
    "# Create own random initial weight and bais\n",
    "w1 = torch.randn(784, 256)\n",
    "b1 = torch.randn(256)\n",
    "\n",
    "w2 = torch.randn(256, 10)\n",
    "b2 = torch.randn(10)\n",
    "\n",
    "h = activation(torch.mm(inputs, w1) + b1)\n",
    " # output of your network, should have shape (64,10)\n",
    "out = torch.mm(h, w2) + b2\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 10 outputs for our network. We want to pass in an image to our network and get out a probability distribution over the classes that tells us the likely class(es) the image belongs to. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: \n",
    "### Implement a function softmax that performs the softmax calculation and returns probability distributions for each example in the batch. \n",
    "\n",
    "### Note :\n",
    "that you'll need to pay attention to the shapes when doing this. If you have a tensor a with shape (64, 10) and a tensor b with shape (64,), doing a/b will give you an error because PyTorch will try to do the division across the columns (called broadcasting) but you'll get a size mismatch. The way to think about this is for each of the 64 examples, you only want to divide by one value, the sum in the denominator. So you need b to have a shape of (64, 1). This way PyTorch will divide the 10 values in each row of a by the one value in each row of b. Pay attention to how you take the sum as well. You'll need to define the dim keyword in torch.sum. Setting dim=0 takes the sum across the rows while dim=1 takes the sum across the columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To calculate this probability distribution, we often use the softmax function. Mathematically this looks like\n",
    "\n",
    "$$\n",
    "\\Large \\sigma(x_i) = \\cfrac{e^{x_i}}{\\sum_k^K{e^{x_k}}}\n",
    "$$\n",
    "#### What this does is squish each input $x_i$ between 0 and 1 and normalizes the values to give you a proper probability distribution where the probabilites sum up to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "source": [
    "# Decalre softmax function\n",
    "\n",
    "def softmax(x):\n",
    "    return torch.exp(x)/torch.sum(torch.exp(x),dim =1).view(-1,1)\n",
    "\n",
    "probablity = softmax(out)\n",
    "\n",
    "# Check if it has the shape (64,10)\n",
    "print(probablity.shape)\n",
    "\n",
    "# Sum to 1\n",
    "print(probablity.sum(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building networks with PyTorch\n",
    "PyTorch provides a module nn that makes building networks much simpler. Here I'll show you how to build the same one as above with 784 inputs, 256 hidden units, 10 output units and a softmax output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Inputs to hidden layer linear transformation\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        \n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "        # Define sigmoid activation and softmax output \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass the input tensor through each of our operations\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the network and look at it's text representation\n",
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Simpler and clean and most commonly used way\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Inputs to hidden layer linear transformation\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Hidden layer with sigmoid activation\n",
    "        x = F.sigmoid(self.hidden(x))\n",
    "        # Output layer with softmax activation\n",
    "        x = F.softmax(self.output(x), dim=1)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: \n",
    "### Create a network with 784 input units, a hidden layer with 128 units and a ReLU activation, then a hidden layer with 64 units and a ReLU activation, and finally an output layer with a softmax activation as shown above. You can use a ReLU activation with the nn.ReLU module or  F.relu function.\n",
    "\n",
    "##### It's good practice to name your layers by their type of network, for instance 'fc' to represent a fully-connected layer. As you code your solution, use fc1, fc2, and fc3 as your layer names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Solution\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Defining layer \n",
    "        # I/p layer 784 , Hidden layer1 128 ,Hidden layer2 64 , softmax 10\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128,64)\n",
    "            \n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass the input tensor through each of our operations\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using **nn.Sequential**\n",
    "\n",
    "#### PyTorch provides a convenient way to build networks like this where a tensor is passed sequentially through operations, nn.Sequential (documentation). Using this to build the equivalent network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (5): Softmax()\n",
      ")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 226,
       "width": 423
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hyperparameters for our network\n",
    "input_size = 784\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 10\n",
    "\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),\n",
    "                      nn.Softmax(dim=1))\n",
    "print(model)\n",
    "\n",
    "# Forward pass through the network and display output\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "ps = model.forward(images[0,:])\n",
    "helper.view_classify(images[0].view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=128, bias=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0109,  0.0158, -0.0309,  ...,  0.0175,  0.0074, -0.0205],\n",
       "        [-0.0252, -0.0353,  0.0079,  ..., -0.0205,  0.0070, -0.0052],\n",
       "        [ 0.0057, -0.0334,  0.0204,  ..., -0.0234, -0.0020, -0.0010],\n",
       "        ...,\n",
       "        [ 0.0119,  0.0007,  0.0099,  ...,  0.0302,  0.0081,  0.0260],\n",
       "        [-0.0123, -0.0343, -0.0029,  ...,  0.0044, -0.0043, -0.0140],\n",
       "        [ 0.0119, -0.0111,  0.0202,  ..., -0.0220, -0.0099,  0.0109]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(model[0])\n",
    "model[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (softmax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "model = nn.Sequential(OrderedDict([\n",
    "                      ('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
    "                      ('relu1', nn.ReLU()),\n",
    "                      ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
    "                      ('relu2', nn.ReLU()),\n",
    "                      ('output', nn.Linear(hidden_sizes[1], output_size)),\n",
    "                      ('softmax', nn.Softmax(dim=1))]))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=128, bias=True)\n",
      "Linear(in_features=784, out_features=128, bias=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(model[0])\n",
    "print(model.fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
